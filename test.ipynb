{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Big Data\n",
    "Théo Dupuis - Clement Frade - Yann Moulaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des données via Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('pbd-cty')\n",
    "s3.Object(bucket.name,'predict.csv').download_file('predict.csv')\n",
    "s3.Object(bucket.name,'train.csv').download_file('train.csv')\n",
    "\n",
    "predict = pd.read_csv(\"predict.csv\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "os.remove(\"predict.csv\")\n",
    "os.remove(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "predict = pd.read_csv(\"predict.csv\")\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division de la base en entraînement et en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "train = train.fillna(0)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "train.Product_Info_2 = le.fit_transform(train.Product_Info_2.astype(str))\n",
    "train.InsuredInfo_7 = le.fit_transform(train.InsuredInfo_7.astype(str))\n",
    "train.InsuredInfo_8 = le.fit_transform(train.InsuredInfo_8.astype(str))\n",
    "train.InsuredInfo_9 = le.fit_transform(train.InsuredInfo_9.astype(str))\n",
    "\n",
    "X = train.drop(columns='Response')\n",
    "y = train.Response\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(.2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation du calcul des scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def score(model, X_test, y_test):\n",
    "    return r2_score(y_test, model.predict(X_test).round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Les différents algorithmes mis en place vont être testés afin de savoir lequel correspond le mieux à nos attentes. Au lieu de, classiquement, tester la précision des méthodes en validant si oui ou non elles appartiennent à la classe qui leur est attribuée (entre 1 et 8), on va prendre en compte la distance de la valeur donnée par rapport à celle voulue. En effet, si un risque est calculé à 2 alors que l'on voulait 3, ce n'est pas grave. En revanche, si un risque est calculé à 8 alors qu'il aurait dû être à 2, c'est une erreur importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "KNN = KNeighborsRegressor()\n",
    "KNN.fit(X_train, y_train)\n",
    "print(\"KNN score avec 5 voisins: \",score(KNN,X_test,y_test),\"score de train\",score(KNN,X_train,y_train))\n",
    "scores.append(score(KNN,X_test,y_test))\n",
    "\n",
    "KNN = KNeighborsRegressor(n_neighbors= 25)\n",
    "KNN.fit(X_train, y_train)\n",
    "print(\"KNN score avec 25 voisins: \",score(KNN,X_test,y_test),\"score de train\",score(KNN,X_train,y_train))\n",
    "scores.append(score(KNN,X_test,y_test))\n",
    "\n",
    "KNN = KNeighborsRegressor(n_neighbors= 1)\n",
    "KNN.fit(X_train, y_train)\n",
    "print(\"KNN score avec 1 seul voisin: \",score(KNN,X_test,y_test),\"score de train\",score(KNN,X_train,y_train))\n",
    "scores.append(score(KNN,X_test,y_test))\n",
    "\n",
    "KNN = KNeighborsRegressor(n_neighbors= 100)\n",
    "KNN.fit(X_train, y_train)\n",
    "print(\"KNN score avec 100 voisins: \",score(KNN,X_test,y_test),\"score de train\",score(KNN,X_train,y_train))\n",
    "scores.append(score(KNN,X_test,y_test))\n",
    "\n",
    "KNN = KNeighborsRegressor(n_neighbors= 200)\n",
    "KNN.fit(X_train, y_train)\n",
    "print(\"KNN score avec 200 voisins: \",score(KNN,X_test,y_test),\"score de train\",score(KNN,X_train,y_train))\n",
    "scores.append(score(KNN,X_test,y_test))\n",
    "\n",
    "KNN = KNeighborsRegressor(n_neighbors= 50)\n",
    "KNN.fit(X_train, y_train)\n",
    "print(\"KNN score avec\",50,\" voisins: \",score(KNN,X_test,y_test),\"score de train\",score(KNN,X_train,y_train))\n",
    "scores.append(score(KNN,X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Linear = LogisticRegression(solver='lbfgs', max_iter = 500)\n",
    "Linear.fit(X_train,y_train)\n",
    "print(\"Linear model avec C=1 score: \",score(Linear,X_test,y_test),\"score de train\",score(Linear,X_train,y_train))\n",
    "scores.append(score(Linear,X_test,y_test))\n",
    "\n",
    "Linear = LogisticRegression(solver='lbfgs', C=0.2, max_iter = 1000)\n",
    "Linear.fit(X_train,y_train)\n",
    "print(\"Linear model avec C=0.2 score: \",score(Linear,X_test,y_test),\"score de train\",score(Linear,X_train,y_train))\n",
    "scores.append(score(Linear,X_test,y_test))\n",
    "\n",
    "Linear = LogisticRegression(solver='lbfgs', C=5, max_iter = 1000)\n",
    "Linear.fit(X_train,y_train)\n",
    "print(\"Linear model avec C=5 score: \",score(Linear,X_test,y_test),\"score de train\",score(Linear,X_train,y_train))\n",
    "scores.append(score(Linear,X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "Tree = DecisionTreeRegressor(min_samples_split= 2)\n",
    "Tree.fit(X_train,y_train)\n",
    "print(\"Decision tree avec min_samples_split=\",2,\" score: \",score(Tree,X_test,y_test),\"score de train\",score(Tree,X_train,y_train))\n",
    "scores.append(score(Tree,X_test,y_test))\n",
    "\n",
    "Tree = DecisionTreeRegressor(min_samples_split= 50)\n",
    "Tree.fit(X_train,y_train)\n",
    "print(\"Decision tree avec min_samples_split=\",50,\" score: \",score(Tree,X_test,y_test),\"score de train\",score(Tree,X_train,y_train))\n",
    "scores.append(score(Tree,X_test,y_test))\n",
    "\n",
    "Tree = DecisionTreeRegressor(min_samples_split= 100)\n",
    "Tree.fit(X_train,y_train)\n",
    "print(\"Decision tree avec min_samples_split=\",100,\" score: \",score(Tree,X_test,y_test),\"score de train\",score(Tree,X_train,y_train))\n",
    "scores.append(score(Tree,X_test,y_test))\n",
    "\n",
    "for i in range (700,1000,25):\n",
    "    Tree = DecisionTreeRegressor(min_samples_split= i)\n",
    "    Tree.fit(X_train,y_train)\n",
    "    print(\"Decision tree avec min_samples_split=\",i,\" score: \",score(Tree,X_test,y_test),\"score de train\",score(Tree,X_train,y_train))\n",
    "    scores.append(score(Tree,X_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine à support de vecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train,y_train)\n",
    "print(\"SVM score: \",score(svm,X_test,y_test),score(svm,X_train,y_train))\n",
    "scores.append(score(svm,X_test,y_test))\n",
    "\n",
    "svm = LinearSVC(C=0.1)\n",
    "svm.fit(X_train,y_train)\n",
    "print(\"SVM score: \",score(svm,X_test,y_test),score(svm,X_train,y_train))\n",
    "scores.append(score(svm,X_test,y_test))\n",
    "\n",
    "svm = LinearSVC(C=10)\n",
    "svm.fit(X_train,y_train)\n",
    "print(\"SVM score: \",score(svm,X_test,y_test),score(svm,X_train,y_train))\n",
    "scores.append(score(svm,X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Multi-couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn_adam = MLPClassifier(solver=\"adam\", hidden_layer_sizes=(100,50), max_iter=3000)\n",
    "nn_adam.fit(X_train, y_train)\n",
    "print(\"Adam\")\n",
    "print(\"  Train accuracy:\", nn_adam.score(X_train, y_train))\n",
    "print(\"  Test  accuracy:\", nn_adam.score(X_test, y_test))\n",
    "print(\"score:\", score(nn_adam,X_test,y_test))\n",
    "\n",
    "nn_sgd = MLPClassifier(solver=\"sgd\", max_iter=3000)\n",
    "nn_sgd.fit(X_train, y_train)\n",
    "print(\"SGD\")\n",
    "print(\"  Train accuracy:\", nn_sgd.score(X_train, y_train))\n",
    "print(\"  Test  accuracy:\", nn_sgd.score(X_test, y_test))\n",
    "print(\"score:\", score(nn_sgd,X_test,y_test))\n",
    "\n",
    "nn_lbfgs = MLPClassifier(solver=\"lbfgs\")\n",
    "nn_lbfgs.fit(X_train, y_train)\n",
    "print(\"LBFGS\")\n",
    "print(\"  Train accuracy:\", nn_lbfgs.score(X_train, y_train))\n",
    "print(\"  Test  accuracy:\", nn_lbfgs.score(X_test, y_test))\n",
    "print(\"score:\", score(nn_lbfgs,X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model Using joblib\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import joblib\n",
    "\n",
    "# Fit the model on training set\n",
    "model = KNN = KNeighborsRegressor(n_neighbors= 50)\n",
    "model.fit(X_train,y_train)\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
